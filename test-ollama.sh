#!/bin/bash
# Ollama æµ‹è¯•è„šæœ¬
# æµ‹è¯•æœ¬åœ°Ollama AI

echo "ğŸ¦™ Testing Ollama with Llama 3.2..."
echo "================================="

# è®¾ç½®ç¯å¢ƒå˜é‡
export AI_ENGINE="ollama"
export AI_BASE_URL="http://localhost:11434"
export AI_MODEL="llama3.2:latest"

echo "Engine: $AI_ENGINE"
echo "Model: $AI_MODEL"
echo "Base URL: $AI_BASE_URL"
echo ""

# æ£€æŸ¥Ollamaæ˜¯å¦è¿è¡Œ
if ! curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "âŒ Error: Ollama is not running on localhost:11434"
    echo "Please start Ollama first:"
    echo "  ollama serve"
    echo "  ollama pull llama3.2:latest"
    exit 1
fi

echo "âœ… Ollama is running"
echo ""

# æ‰§è¡Œæµ‹è¯•
gemini "Hello, please introduce yourself and tell me which AI model you are. Please respond in English."

