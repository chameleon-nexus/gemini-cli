/**
 * @license
 * Copyright 2025 Google LLC
 * SPDX-License-Identifier: Apache-2.0
 */

/**
 * @author chameleon-nexus
 * @email mythicscribe2014@gmail.com
 */

import type {
  Content,
  CountTokensParameters,
  CountTokensResponse,
  EmbedContentParameters,
  EmbedContentResponse,
  FunctionCall,
  GenerateContentParameters,
  GenerateContentResponse,
  Part,
  Tool,
} from '@google/genai';
import type { ContentGenerator } from './contentGenerator.js';

// å·¥å…·æ‰§è¡Œå™¨ç±»å‹å®šä¹‰
export type ToolExecutor = {
  [functionName: string]: (...args: any[]) => Promise<any> | any;
};

// å·¥å…·æ‰§è¡Œç»“æœç±»å‹
type ToolExecutionResult = {
  success: boolean;
  result?: any;
  error?: string;
};

type GlmTool = {
  type: 'function';
  function: {
    name: string;
    description?: string;
    parameters?: unknown;
  };
};

type GlmToolCall = {
  id?: string;
  type: 'function';
  function: {
    name: string;
    arguments: string;
  };
};

type GlmMessage = {
  role: 'system' | 'user' | 'assistant' | 'tool';
  content?: string | GlmMessageContentBlock[] | null;
  name?: string;
  tool_call_id?: string;
  tool_calls?: GlmToolCall[];
};

type GlmMessageContentBlock = {
  type?: string;
  text?: string;
};

type GlmChoice = {
  index?: number;
  message: GlmMessage;
  finish_reason?: string;
};

type GlmUsage = {
  prompt_tokens?: number;
  completion_tokens?: number;
  total_tokens?: number;
};

type GlmResponse = {
  choices: GlmChoice[];
  usage?: GlmUsage;
};

/**
 * Zhipu AI GLM ContentGenerator implementation
 * Supports accessing GLM series models through Zhipu AI official API
 */
export class GlmContentGenerator implements ContentGenerator {
  private readonly baseUrl: string;
  private readonly apiKey: string;
  private readonly model: string;
  private readonly toolExecutors: ToolExecutor;

  constructor(toolExecutors: ToolExecutor = {}) {
    // Unified environment variable support, prioritize engine-specific variables, fallback to generic variables
    this.baseUrl = process.env['GLM_BASE_URL'] || process.env['AI_BASE_URL'] || 'https://open.bigmodel.cn/api/paas/v4';
    this.apiKey = process.env['GLM_API_KEY'] || process.env['ZHIPU_API_KEY'] || process.env['AI_API_KEY'] || (() => {
      throw new Error('API key not found. Please set one of: GLM_API_KEY, ZHIPU_API_KEY, or AI_API_KEY environment variable.');
    })();
    this.model = process.env['GLM_MODEL'] || process.env['AI_MODEL'] || 'glm-4';
    this.toolExecutors = toolExecutors;
    
    console.log('ğŸ§  Zhipu AI GLM ContentGenerator: Initialized successfully');
    console.log(`   Model: ${this.model}`);
    console.log(`   API Endpoint: ${this.baseUrl}`);
    console.log(`   Provider: Zhipu AI`);
    console.log(`   Available Tools: ${Object.keys(toolExecutors).length} functions`);
    if (Object.keys(toolExecutors).length > 0) {
      console.log(`   - ${Object.keys(toolExecutors).join(', ')}`);
    }
  }

  async generateContent(
    request: GenerateContentParameters,
    _userPromptId: string,
  ): Promise<GenerateContentResponse> {
    try {
      // è½¬æ¢è¯·æ±‚æ ¼å¼
      const glmRequest = this.buildGlmRequestPayload(request, false);

      // è°ƒç”¨æ™ºè°±AI API
      const response = await fetch(`${this.baseUrl}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`,
        },
        body: JSON.stringify(glmRequest),
        signal: request.config?.abortSignal
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`æ™ºè°±AI GLM API error: ${response.status} ${errorText}`);
      }

      const glmResponse: GlmResponse = await response.json();
      // è½¬æ¢å“åº”æ ¼å¼å¹¶æ‰§è¡Œå·¥å…·è°ƒç”¨
      return await this.convertGlmToGemini(glmResponse, true);

    } catch (error) {
      console.error('æ™ºè°±AI GLM API call failed:', error);
      throw error;
    }
  }

  async generateContentStream(
    request: GenerateContentParameters,
    _userPromptId: string,
  ): Promise<AsyncGenerator<GenerateContentResponse>> {
    try {
      // æ™ºè°±AIæ”¯æŒåŸç”Ÿæµå¼å“åº”
      const glmRequest = this.buildGlmRequestPayload(request, true);

      const response = await fetch(`${this.baseUrl}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`,
        },
        body: JSON.stringify(glmRequest),
        signal: request.config?.abortSignal
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`æ™ºè°±AI GLM Stream API error: ${response.status} ${errorText}`);
      }

      return this.handleGlmStream(response);

    } catch (error) {
      console.error('æ™ºè°±AI GLM Stream API call failed:', error);
      // å¦‚æœæµå¼å¤±è´¥ï¼Œå›é€€åˆ°éæµå¼
      const response = await this.generateContent(request, _userPromptId);
      return this.simulateStream(response);
    }
  }

  async countTokens(request: CountTokensParameters): Promise<CountTokensResponse> {
    // æ™ºè°±AIæä¾›tokenè®¡ç®—æ¥å£
    try {
      const messages = this.convertGeminiToGlmMessages(
        this.normalizeContents(request.contents as any),
      );

      const response = await fetch(`${this.baseUrl}/token/encode`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`,
        },
        body: JSON.stringify({
          model: this.model,
          messages
        })
      });

      if (response.ok) {
        const result = await response.json();
        return {
          totalTokens: result.tokens?.length || 0,
        };
      }
    } catch (error) {
      console.warn('æ™ºè°±AI token counting failed, using estimation:', error);
    }

    // å›é€€åˆ°ä¼°ç®—
    const text = JSON.stringify(request);
    const estimatedTokens = Math.ceil(text.length / 4);
    
    return {
      totalTokens: estimatedTokens,
    };
  }

  async embedContent(request: EmbedContentParameters): Promise<EmbedContentResponse> {
    throw new Error('Embedding not supported by GLM implementation');
  }

  /**
   * æ‰§è¡Œå‡½æ•°è°ƒç”¨
   * @param functionCall å‡½æ•°è°ƒç”¨ä¿¡æ¯
   * @returns æ‰§è¡Œç»“æœ
   */
  private async executeFunctionCall(functionCall: FunctionCall): Promise<ToolExecutionResult> {
    const { name, args } = functionCall;
    
    console.log(`ğŸ”§ æ‰§è¡Œå·¥å…·è°ƒç”¨: ${name}`, args);
    
    try {
      // å®‰å…¨æ£€æŸ¥ï¼šå‡½æ•°åéªŒè¯
      if (!name || typeof name !== 'string') {
        const error = 'æ— æ•ˆçš„å‡½æ•°å';
        console.error(`âŒ ${error}:`, name);
        return { success: false, error };
      }

      // å®‰å…¨æ£€æŸ¥ï¼šå‡½æ•°åé•¿åº¦é™åˆ¶
      if (name.length > 100) {
        const error = 'å‡½æ•°åè¿‡é•¿ï¼Œå¯èƒ½å­˜åœ¨å®‰å…¨é£é™©';
        console.error(`âŒ ${error}:`, name);
        return { success: false, error };
      }

      // å®‰å…¨æ£€æŸ¥ï¼šå‡½æ•°ååªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿
      if (!/^[a-zA-Z_][a-zA-Z0-9_]*$/.test(name)) {
        const error = 'å‡½æ•°ååŒ…å«éæ³•å­—ç¬¦';
        console.error(`âŒ ${error}:`, name);
        return { success: false, error };
      }

      const executor = this.toolExecutors[name];
      if (!executor) {
        const error = `å·¥å…· "${name}" æœªæ‰¾åˆ°å¯ç”¨çš„æ‰§è¡Œå™¨`;
        console.error(`âŒ ${error}`);
        return { success: false, error };
      }

      if (typeof executor !== 'function') {
        const error = `å·¥å…· "${name}" çš„æ‰§è¡Œå™¨ä¸æ˜¯æœ‰æ•ˆå‡½æ•°`;
        console.error(`âŒ ${error}`);
        return { success: false, error };
      }

      // å‚æ•°å®‰å…¨æ£€æŸ¥
      const safeArgs = this.validateFunctionArgs(args);
      if (!safeArgs.valid) {
        console.error(`âŒ å·¥å…· "${name}" å‚æ•°éªŒè¯å¤±è´¥:`, safeArgs.error);
        return { success: false, error: safeArgs.error };
      }

      // è®¾ç½®æ‰§è¡Œè¶…æ—¶
      const timeoutMs = 30000; // 30ç§’è¶…æ—¶
      const timeoutPromise = new Promise<never>((_, reject) => {
        setTimeout(() => reject(new Error(`å·¥å…· "${name}" æ‰§è¡Œè¶…æ—¶ (${timeoutMs}ms)`)), timeoutMs);
      });

      // æ‰§è¡Œå·¥å…·å‡½æ•°ï¼ˆå¸¦è¶…æ—¶æ§åˆ¶ï¼‰
      const executionPromise = executor(safeArgs.args || {});
      const result = await Promise.race([executionPromise, timeoutPromise]);
      
      console.log(`âœ… å·¥å…· "${name}" æ‰§è¡ŒæˆåŠŸ:`, result);
      
      return { success: true, result };
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      console.error(`âŒ å·¥å…· "${name}" æ‰§è¡Œå¤±è´¥:`, errorMessage);
      
      // è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
      if (error instanceof Error && error.stack) {
        console.debug(`å·¥å…· "${name}" é”™è¯¯å †æ ˆ:`, error.stack);
      }
      
      return { success: false, error: errorMessage };
    }
  }

  /**
   * éªŒè¯å‡½æ•°å‚æ•°çš„å®‰å…¨æ€§
   * @param args å‡½æ•°å‚æ•°
   * @returns éªŒè¯ç»“æœ
   */
  private validateFunctionArgs(args: any): { valid: boolean; args?: any; error?: string } {
    try {
      // æ£€æŸ¥å‚æ•°æ˜¯å¦å­˜åœ¨
      if (args === undefined || args === null) {
        return { valid: true, args: {} };
      }

      // æ£€æŸ¥å‚æ•°ç±»å‹
      if (typeof args !== 'object' || Array.isArray(args)) {
        return { valid: false, error: 'å‚æ•°å¿…é¡»æ˜¯å¯¹è±¡ç±»å‹' };
      }

      // æ£€æŸ¥å‚æ•°æ·±åº¦ï¼ˆé˜²æ­¢è¿‡æ·±çš„åµŒå¥—ï¼‰
      const maxDepth = 10;
      if (!this.checkObjectDepth(args, maxDepth)) {
        return { valid: false, error: `å‚æ•°åµŒå¥—å±‚çº§è¶…è¿‡ ${maxDepth} å±‚` };
      }

      // æ£€æŸ¥JSONåºåˆ—åŒ–å¤§å°ï¼ˆé˜²æ­¢è¿‡å¤§çš„å‚æ•°ï¼‰
      const jsonString = JSON.stringify(args);
      const maxSize = 1024 * 1024; // 1MB
      if (jsonString.length > maxSize) {
        return { valid: false, error: `å‚æ•°å¤§å°è¶…è¿‡ ${maxSize} å­—ç¬¦` };
      }

      // æ£€æŸ¥å±é™©å±æ€§ï¼ˆåŸºç¡€å®‰å…¨è¿‡æ»¤ï¼‰
      const dangerousKeys = ['__proto__', 'constructor', 'prototype'];
      if (this.containsDangerousKeys(args, dangerousKeys)) {
        return { valid: false, error: 'å‚æ•°åŒ…å«å±é™©å±æ€§' };
      }

      return { valid: true, args };
    } catch (error) {
      return { valid: false, error: `å‚æ•°éªŒè¯å¤±è´¥: ${error instanceof Error ? error.message : String(error)}` };
    }
  }

  /**
   * æ£€æŸ¥å¯¹è±¡åµŒå¥—æ·±åº¦
   * @param obj è¦æ£€æŸ¥çš„å¯¹è±¡
   * @param maxDepth æœ€å¤§æ·±åº¦
   * @param currentDepth å½“å‰æ·±åº¦
   * @returns æ˜¯å¦åœ¨å…è®¸çš„æ·±åº¦å†…
   */
  private checkObjectDepth(obj: any, maxDepth: number, currentDepth: number = 0): boolean {
    if (currentDepth > maxDepth) {
      return false;
    }

    if (typeof obj === 'object' && obj !== null && !Array.isArray(obj)) {
      for (const value of Object.values(obj)) {
        if (typeof value === 'object' && value !== null) {
          if (!this.checkObjectDepth(value, maxDepth, currentDepth + 1)) {
            return false;
          }
        }
      }
    }

    return true;
  }

  /**
   * æ£€æŸ¥å¯¹è±¡æ˜¯å¦åŒ…å«å±é™©å±æ€§
   * @param obj è¦æ£€æŸ¥çš„å¯¹è±¡
   * @param dangerousKeys å±é™©å±æ€§åˆ—è¡¨
   * @returns æ˜¯å¦åŒ…å«å±é™©å±æ€§
   */
  private containsDangerousKeys(obj: any, dangerousKeys: string[]): boolean {
    if (typeof obj !== 'object' || obj === null) {
      return false;
    }

    for (const key of Object.keys(obj)) {
      if (dangerousKeys.includes(key)) {
        return true;
      }

      if (typeof obj[key] === 'object' && obj[key] !== null) {
        if (this.containsDangerousKeys(obj[key], dangerousKeys)) {
          return true;
        }
      }
    }

    return false;
  }

  /**
   * æ‰¹é‡æ‰§è¡Œå¤šä¸ªå‡½æ•°è°ƒç”¨
   * @param functionCalls å‡½æ•°è°ƒç”¨åˆ—è¡¨
   * @returns æ‰§è¡Œç»“æœåˆ—è¡¨
   */
  private async executeFunctionCalls(functionCalls: FunctionCall[]): Promise<ToolExecutionResult[]> {
    const results: ToolExecutionResult[] = [];
    
    for (const call of functionCalls) {
      const result = await this.executeFunctionCall(call);
      results.push(result);
    }
    
    return results;
  }

  private buildGlmRequestPayload(
    request: GenerateContentParameters,
    stream: boolean,
  ): {
    model: string;
    messages: GlmMessage[];
    temperature?: number;
    max_tokens?: number;
    top_p?: number;
    stream: boolean;
    tools?: GlmTool[];
    tool_choice?: 'auto' | 'none';
  } {
    const messages = this.convertGeminiToGlmMessages(
      this.normalizeContents(request.contents as any),
    );
    const payload: {
      model: string;
      messages: GlmMessage[];
      temperature?: number;
      max_tokens?: number;
      top_p?: number;
      stream: boolean;
      tools?: GlmTool[];
      tool_choice?: 'auto' | 'none';
    } = {
      model: this.model,
      messages,
      temperature: request.config?.temperature,
      max_tokens: request.config?.maxOutputTokens,
      top_p: request.config?.topP,
      stream,
    };

    const tools = this.convertTools(request.config?.tools as Tool[]);
    if (tools.length > 0) {
      payload.tools = tools;
      payload.tool_choice = 'auto';
    }

    return payload;
  }

  private convertGeminiToGlmMessages(contents: Content[]): GlmMessage[] {
    const messages: GlmMessage[] = [];

    for (const content of contents) {
      const textParts: string[] = [];
      const toolCalls: GlmToolCall[] = [];

      for (const part of content.parts ?? []) {
        if (part.text && part.text.trim()) {
          textParts.push(part.text);
        }

        if (part.functionCall) {
          toolCalls.push({
            id: part.functionCall.id || `call_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
            type: 'function',
            function: {
              name: part.functionCall.name || 'unknown_function',
              arguments: JSON.stringify(part.functionCall.args ?? {}),
            },
          });
        }

        if (part.functionResponse) {
          messages.push({
            role: 'tool',
            tool_call_id: part.functionResponse.id || 'unknown',
            content: this.serializeFunctionResponse(part.functionResponse),
          });
        }
      }

      const text = textParts.join('\n').trim();
      if (text || toolCalls.length > 0) {
        const role = content.role === 'model' ? 'assistant' : (content.role as 'system' | 'user' | 'assistant' | 'tool');
        messages.push({
          role,
          content: text || undefined,
          tool_calls: toolCalls.length > 0 ? toolCalls : undefined,
        });
      }
    }

    return messages;
  }

  private convertTools(tools?: Tool[]): GlmTool[] {
    if (!tools) {
      return [];
    }

    const result: GlmTool[] = [];
    for (const tool of tools) {
      for (const declaration of tool.functionDeclarations ?? []) {
        if (!declaration?.name) {
          continue;
        }
        
        // å¢å¼ºå·¥å…·æè¿°ï¼Œå‘æ¨¡å‹è¯´æ˜è¿™æ˜¯å®é™…å¯æ‰§è¡Œçš„å·¥å…·
        const enhancedDescription = declaration.description 
          ? `${declaration.description} [å¯æ‰§è¡Œå·¥å…· - æˆ‘ä¼šå®é™…è°ƒç”¨æ­¤åŠŸèƒ½]`
          : `${declaration.name} - å®é™…å¯æ‰§è¡Œçš„å·¥å…·å‡½æ•°`;
          
        result.push({
          type: 'function',
          function: {
            name: declaration.name,
            description: enhancedDescription,
            parameters: declaration.parameters,
          },
        });
      }
    }
    
    console.log(`ğŸ”§ GLMå·¥å…·è½¬æ¢å®Œæˆ: å·²å‡†å¤‡ ${result.length} ä¸ªå¯æ‰§è¡Œå·¥å…·`);
    result.forEach(tool => {
      console.log(`   - ${tool.function.name}: ${tool.function.description}`);
    });
    
    return result;
  }

  private async convertGlmToGemini(glmResponse: GlmResponse, executeTools: boolean = true): Promise<GenerateContentResponse> {
    const choice = glmResponse.choices?.[0];
    if (!choice) {
      throw new Error('GLM response did not contain any choices.');
    }

    const parts: Part[] = [];
    const functionCalls: FunctionCall[] = [];
    const message = choice.message;
    
    // å¤„ç†å·¥å…·è°ƒç”¨
    if (message.tool_calls && message.tool_calls.length > 0) {
      console.log(`ğŸ”§ GLMè¿”å›äº† ${message.tool_calls.length} ä¸ªå·¥å…·è°ƒç”¨`);
      
      for (const toolCall of message.tool_calls) {
        const args = this.safeParseJson(toolCall.function.arguments);
        const call: FunctionCall = {
          id: toolCall.id || `call_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
          name: toolCall.function.name,
          args,
        };
        functionCalls.push(call);
        parts.push({ functionCall: call });
        
        console.log(`ğŸ“‹ å·¥å…·è°ƒç”¨: ${call.name}`, call.args);
      }

      // å¦‚æœå¯ç”¨äº†å·¥å…·æ‰§è¡Œï¼Œåˆ™è‡ªåŠ¨æ‰§è¡Œå·¥å…·è°ƒç”¨
      if (executeTools && Object.keys(this.toolExecutors).length > 0) {
        console.log('ğŸš€ å¼€å§‹æ‰§è¡Œå·¥å…·è°ƒç”¨...');
        const executionResults = await this.executeFunctionCalls(functionCalls);
        
        // å°†æ‰§è¡Œç»“æœæ·»åŠ åˆ°partsä¸­
        for (let i = 0; i < functionCalls.length; i++) {
          const call = functionCalls[i];
          const result = executionResults[i];
          
          if (result) {
            parts.push({
              functionResponse: {
                id: call.id,
                name: call.name,
                response: {
                  success: result.success,
                  result: result.result,
                  error: result.error,
                  timestamp: new Date().toISOString()
                }
              }
            });
          }
        }
        
        console.log('âœ… å·¥å…·æ‰§è¡Œå®Œæˆ');
      }
    }

    const textContent = this.extractAssistantText(message.content);
    if (textContent) {
      parts.push({ text: textContent });
    }

    const usage = glmResponse.usage ?? {};

    return {
      candidates: [
        {
          content: {
            role: 'model',
            parts,
          },
          finishReason: this.mapFinishReason(choice.finish_reason ?? 'stop'),
          index: choice.index ?? 0,
        },
      ],
      functionCalls: functionCalls.length > 0 ? functionCalls : undefined,
      text: textContent ?? undefined,
      usageMetadata: {
        promptTokenCount: usage.prompt_tokens ?? 0,
        candidatesTokenCount: usage.completion_tokens ?? 0,
        totalTokenCount: usage.total_tokens ?? 0,
      },
    } as GenerateContentResponse;
  }

  private async* handleGlmStream(response: Response): AsyncGenerator<GenerateContentResponse> {
    const reader = response.body?.getReader();
    const decoder = new TextDecoder();

    if (!reader) {
      throw new Error('Stream reader not available');
    }

    // ç´¯ç§¯å·¥å…·è°ƒç”¨æ•°æ®
    let accumulatedToolCalls: GlmToolCall[] = [];
    let streamFinished = false;

    try {
      while (true) {
        const { done, value } = await reader.read();
        
        if (done) {
          streamFinished = true;
          break;
        }

        const chunk = decoder.decode(value);
        const lines = chunk.split('\n');

        for (const line of lines) {
          if (line.startsWith('data: ') && !line.includes('[DONE]')) {
            try {
              const data = JSON.parse(line.slice(6));
              const choice = data.choices?.[0];
              
              if (!choice) continue;

              // å¤„ç†æ™®é€šæ–‡æœ¬å†…å®¹
              if (choice.delta?.content) {
                yield {
                  candidates: [{
                    content: {
                      role: 'model',
                      parts: [{ text: choice.delta.content }],
                    },
                    finishReason: 'STOP' as any,
                    index: 0,
                  }],
                } as GenerateContentResponse;
              }

              // å¤„ç†å·¥å…·è°ƒç”¨ï¼ˆGLMåœ¨æµå¼ä¸­å¯èƒ½åˆ†å—å‘é€tool_callsï¼‰
              if (choice.delta?.tool_calls) {
                for (const toolCall of choice.delta.tool_calls) {
                  // æŸ¥æ‰¾æˆ–åˆ›å»ºå·¥å…·è°ƒç”¨
                  let existingCall = accumulatedToolCalls.find(call => call.id === toolCall.id);
                  if (!existingCall) {
                    existingCall = {
                      id: toolCall.id,
                      type: 'function',
                      function: {
                        name: toolCall.function?.name || '',
                        arguments: ''
                      }
                    };
                    accumulatedToolCalls.push(existingCall);
                  }
                  
                  // ç´¯ç§¯å·¥å…·è°ƒç”¨æ•°æ®
                  if (toolCall.function?.name) {
                    existingCall.function.name = toolCall.function.name;
                  }
                  if (toolCall.function?.arguments) {
                    existingCall.function.arguments += toolCall.function.arguments;
                  }
                }
              }

              // æ£€æŸ¥æ˜¯å¦å®Œæˆ
              if (choice.finish_reason) {
                streamFinished = true;
              }
            } catch (e) {
              // å¿½ç•¥è§£æé”™è¯¯
              console.warn('Stream parsing error:', e);
            }
          }
        }
      }

      // æµç»“æŸåï¼Œå¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œå¤„ç†æ‰§è¡Œ
      if (streamFinished && accumulatedToolCalls.length > 0) {
        console.log(`ğŸ”§ æµå¼å¤„ç†å‘ç° ${accumulatedToolCalls.length} ä¸ªå·¥å…·è°ƒç”¨`);
        
        const functionCalls: FunctionCall[] = [];
        const parts: Part[] = [];

        // è½¬æ¢å·¥å…·è°ƒç”¨æ ¼å¼
        for (const toolCall of accumulatedToolCalls) {
          const args = this.safeParseJson(toolCall.function.arguments);
          const call: FunctionCall = {
            id: toolCall.id,
            name: toolCall.function.name,
            args,
          };
          functionCalls.push(call);
          parts.push({ functionCall: call });
        }

        // æ‰§è¡Œå·¥å…·è°ƒç”¨
        if (Object.keys(this.toolExecutors).length > 0) {
          console.log('ğŸš€ æµå¼æ¨¡å¼ï¼šå¼€å§‹æ‰§è¡Œå·¥å…·è°ƒç”¨...');
          const executionResults = await this.executeFunctionCalls(functionCalls);
          
          // æ·»åŠ æ‰§è¡Œç»“æœ
          for (let i = 0; i < functionCalls.length; i++) {
            const call = functionCalls[i];
            const result = executionResults[i];
            
            if (result) {
              parts.push({
                functionResponse: {
                  id: call.id,
                  name: call.name,
                  response: {
                    success: result.success,
                    result: result.result,
                    error: result.error,
                    timestamp: new Date().toISOString()
                  }
                }
              });
            }
          }
          
          console.log('âœ… æµå¼æ¨¡å¼ï¼šå·¥å…·æ‰§è¡Œå®Œæˆ');
        }

        // è¾“å‡ºå·¥å…·è°ƒç”¨ç»“æœ
        yield {
          candidates: [{
            content: {
              role: 'model',
              parts,
            },
            finishReason: 'STOP' as any,
            index: 0,
          }],
          functionCalls,
        } as GenerateContentResponse;
      }

    } finally {
      reader.releaseLock();
    }
  }

  private mapFinishReason(
    reason: string,
  ): NonNullable<GenerateContentResponse['candidates']>[number]['finishReason'] {
    switch (reason) {
      case 'stop':
        return 'STOP' as any;
      case 'length':
        return 'MAX_TOKENS' as any;
      case 'content_filter':
        return 'SAFETY' as any;
      default:
        return 'STOP' as any;
    }
  }

  private async* simulateStream(response: GenerateContentResponse): AsyncGenerator<GenerateContentResponse> {
    const content = response.candidates?.[0]?.content?.parts?.[0]?.text || '';
    const words = content.split(' ');
    const chunkSize = 3; // æ¯æ¬¡è¿”å›3ä¸ªå•è¯ï¼Œæ¨¡æ‹Ÿæµå¼æ•ˆæœ

    for (let i = 0; i < words.length; i += chunkSize) {
      const chunk = words.slice(i, i + chunkSize).join(' ');

      yield {
        candidates: [{
          content: {
            role: 'model',
            parts: [{ text: chunk + (i + chunkSize < words.length ? ' ' : '') }],
          },
          finishReason: 'STOP',
          index: 0,
        }],
      } as GenerateContentResponse;

      // æ·»åŠ å°å»¶è¿Ÿä»¥æ¨¡æ‹Ÿæµå¼è¾“å‡º
      await new Promise((resolve) => setTimeout(resolve, 50));
    }
  }

  private normalizeContents(contents: Content | Content[] | Part[] | Part | string): Content[] {
    if (Array.isArray(contents)) {
      if (contents.length === 0) {
        return [];
      }
      if ('role' in contents[0]!) {
        return contents as Content[];
      }
      return [
        {
          role: 'user',
          parts: this.toPartsList(contents as Part[] | Part),
        },
      ];
    }

    if (typeof contents === 'string') {
      return [
        {
          role: 'user',
          parts: [{ text: contents }],
        },
      ];
    }

    if ('role' in contents) {
      return [contents as Content];
    }

    return [
      {
        role: 'user',
        parts: this.toPartsList(contents as Part[] | Part),
      },
    ];
  }

  private toPartsList(value: Part[] | Part): Part[] {
    if (Array.isArray(value)) {
      return value;
    }
    return [value];
  }

  private serializeFunctionResponse(response: Part['functionResponse']): string {
    if (!response?.response) {
      return '';
    }

    const value = response.response;
    if (typeof value === 'string') {
      return value;
    }

    if (Array.isArray(value)) {
      return value
        .map((item) => {
          if (typeof item === 'string') {
            return item;
          }
          if (item && typeof item === 'object' && 'text' in item) {
            return String((item as { text?: string }).text ?? '');
          }
          return '';
        })
        .join('');
    }

    try {
      return JSON.stringify(value);
    } catch (error) {
      console.warn('Failed to serialize GLM tool response:', error);
      return String(value);
    }
  }

  private safeParseJson(value: string | undefined): Record<string, unknown> {
    if (!value) {
      return {};
    }

    try {
      const parsed = JSON.parse(value);
      return typeof parsed === 'object' && parsed !== null
        ? (parsed as Record<string, unknown>)
        : {};
    } catch (error) {
      console.warn('Failed to parse GLM tool call arguments:', error);
      return {};
    }
  }

  private extractAssistantText(
    content: GlmMessage['content'],
  ): string | undefined {
    if (typeof content === 'string') {
      const trimmed = content.trim();
      return trimmed.length > 0 ? trimmed : undefined;
    }

    if (Array.isArray(content)) {
      const text = content
        .map((block) => (block.text ? block.text.trim() : ''))
        .filter((blockText) => blockText.length > 0)
        .join('');
      return text.length > 0 ? text : undefined;
    }

    return undefined;
  }
}
