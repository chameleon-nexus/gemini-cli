# Gemini CLI (CatalystAI Edition) - Multi-Engine AI-Plattform

[![npm version](https://badge.fury.io/js/%40catalystai%2Fgemini-cli.svg)](https://badge.fury.io/js/%40catalystai%2Fgemini-cli)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)

**ğŸš€ Das weltweit erste einheitliche CLI-Tool mit UnterstÃ¼tzung fÃ¼r 6 groÃŸe AI-Engines - Ein Befehl, alle Modelle**

> âš ï¸ **Wichtiger Hinweis**: Dies ist eine modifizierte Version von [Google Gemini CLI](https://github.com/google-gemini/gemini-cli). Das ursprÃ¼ngliche Projekt ist urheberrechtlich geschÃ¼tzt von Google LLC und folgt der Apache 2.0 Lizenz.

## ğŸŒ Sprachumschaltung / Language Switch

| ğŸ‡ºğŸ‡¸ [English](../README.md) | ğŸ‡¨ğŸ‡³ [ä¸­æ–‡](README.zh.md) | ğŸ‡¯ğŸ‡µ [æ—¥æœ¬èª](README.ja.md) | ğŸ‡©ğŸ‡ª **Deutsch** | ğŸ‡»ğŸ‡³ [Tiáº¿ng Viá»‡t](README.vi.md) | ğŸ‡¸ğŸ‡¦ [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](README.ar.md) |

## ğŸŒŸ Hauptfunktionen

- ğŸ¯ **6 groÃŸe AI-Engine-UnterstÃ¼tzung**: OpenRouterã€Azureã€Ollamaã€Volcengineã€Bailianã€GLM
- ğŸ”„ **Einheitliche Umgebungsvariablen**: Ein Satz Konfigurationen fÃ¼r alle Engines
- ğŸŒ **Globale Modellabdeckung**: UnterstÃ¼tzt GPTã€Claudeã€Qwenã€GLMã€DeepSeek und andere Mainstream-Modelle
- ğŸ  **Lokale AI-UnterstÃ¼tzung**: Ollama lokale Bereitstellung, Daten vollstÃ¤ndig privat
- ğŸ”§ **Null-Konfigurationswechsel**: Ein Umgebungsvariable reicht fÃ¼r Engine-Wechsel
- ğŸ“Š **VollstÃ¤ndige Funktionen**: Streaming/Non-Streamingã€Token-Berechnungã€Embedding-Vektoren vollstÃ¤ndig unterstÃ¼tzt

## ğŸ“¦ Installation

```bash
npm install -g @catalystai/gemini-cli
```

## ğŸ›ï¸ UnterstÃ¼tzte AI-Engines und Modelle

### ğŸŒ OpenRouter (Multi-Model-Routing)
**UnterstÃ¼tzte Modelle**: GPT-4ã€Claudeã€Llamaã€Mistralç­‰
- `anthropic/claude-3.5-sonnet` (Standard)
- `openai/gpt-4`
- `meta-llama/llama-3.1-8b-instruct`
- `mistralai/mistral-7b-instruct`

### â˜ï¸ Azure OpenAI / Azure AI Foundry
**UnterstÃ¼tzte Modelle**: GPT-4ã€GPT-3.5ã€DALL-Eç­‰
- `gpt-4` (Standard)
- `gpt-3.5-turbo`
- `gpt-4-turbo`
- `dall-e-3`

### ğŸ¦™ Ollama (Lokale AI)
**UnterstÃ¼tzte Modelle**: Llamaã€Mistralã€CodeLlamaç­‰
- `llama3.2:latest` (Standard)
- `mistral:latest`
- `codellama:latest`
- `qwen:latest`

### ğŸ”¥ Volcengine (Standard-Engine)
**UnterstÃ¼tzte Modelle**: DeepSeek V3ã€Qwen-Serieã€ChatGLMã€Baichuanç­‰
- `deepseek-v3-250324` (Standard)
- `qwen-plus`
- `qwen-max`
- `chatglm-6b`

### ğŸŒŠ Bailian (é˜¿é‡Œäº‘ç™¾ç‚¼)
**UnterstÃ¼tzte Modelle**: é€šä¹‰åƒé—®å•†ä¸šç‰ˆã€å¤šæ¨¡æ€æ¨¡å‹
- `qwen-plus` (Standard)
- `qwen-max`
- `qwen-vl-plus`

### ğŸ§  GLM (æ™ºè°±AI)
**UnterstÃ¼tzte Modelle**: GLM-4ã€CogViewç­‰
- `glm-4` (Standard)
- `glm-4v`
- `cogview-3`

## âš™ï¸ Einheitliches Konfigurationssystem

### ğŸ”§ Empfohlene Konfigurationsmethode (Einheitliche Umgebungsvariablen)

```bash
# Einheitlicher API-SchlÃ¼ssel (fÃ¼r alle Engines gemeinsam)
export AI_API_KEY="your-actual-api-key-from-your-ai-provider"

# Einheitlicher Modellname (fÃ¼r alle Engines gemeinsam)
export AI_MODEL="your-preferred-model-name"

# Einheitliche Base URL (Optional, nur bei benutzerdefinierten Einstellungen)
export AI_BASE_URL="your-custom-endpoint-url"

# Engine-Auswahl (Eine Variable steuert alles)
export AI_ENGINE="volcengine"  # Optionen: openrouter, azure, ollama, volcengine, bailian, glm
```

### ğŸªŸ Windows PowerShell Konfiguration

```powershell
# Einheitliche Konfiguration
$env:AI_API_KEY="your-actual-api-key-from-your-ai-provider"
$env:AI_MODEL="your-preferred-model-name"
$env:AI_ENGINE="volcengine"
```

### ğŸ”§ Engine-spezifische Konfiguration (Optional)

Bei Verwendung engine-spezifischer Konfigurationen fÃ¤llt das System automatisch auf einheitliche Konfigurationen zurÃ¼ckï¼š

```bash
# OpenRouter spezifische Konfiguration  
export OPENROUTER_API_KEY="your-openrouter-api-key"
export OPENROUTER_MODEL="anthropic/claude-3.5-sonnet"

# Azure spezifische Konfiguration
export AZURE_API_KEY="your-azure-openai-api-key"
export AZURE_BASE_URL="https://your-resource.openai.azure.com"
export AZURE_MODEL="gpt-4"

# Volcengine spezifische Konfiguration
export VOLCENGINE_API_KEY="your-volcengine-api-key"
export VOLCENGINE_MODEL="deepseek-v3-250324"
```

## ğŸš€ Verwendung

### ğŸ’¬ Direkter Frage-Modus

```bash
gemini "Hallo, bitte stelle dich vor"
```

### ğŸ”„ Interaktiver Modus

```bash
gemini
```

WÃ¤hlen Sie dann "2. Use Gemini API Key" und drÃ¼cken Sie Enter, um den Chat zu starten.

## ğŸ§ª Engine-Testbeispiele

### ğŸŒ OpenRouter testen

```bash
# Einheitliche Konfiguration verwenden
export AI_API_KEY="your-openrouter-api-key"
export AI_ENGINE="openrouter"
export AI_MODEL="anthropic/claude-3.5-sonnet"

# Test-Befehl
gemini "Hello, please introduce yourself and tell me which AI model you are."
```

### â˜ï¸ Azure OpenAI testen

```bash
# Einheitliche Konfiguration verwenden
export AI_API_KEY="your-azure-openai-api-key"
export AI_ENGINE="azure"
export AI_BASE_URL="https://your-resource.openai.azure.com"
export AI_MODEL="gpt-4"

# Test-Befehl
gemini "Hello, please introduce yourself and tell me which AI model you are."
```

### ğŸ¦™ Ollama testen (Lokale AI)

```bash
# Einheitliche Konfiguration verwenden
export AI_ENGINE="ollama"
export AI_BASE_URL="http://localhost:11434"
export AI_MODEL="llama3.2:latest"

# Test-Befehl
gemini "Hello, please introduce yourself and tell me which AI model you are."
```

### ğŸ”¥ Volcengine testen (Standard-Engine)

```bash
# Einheitliche Konfiguration verwenden
export AI_API_KEY="your-volcengine-api-key"
export AI_ENGINE="volcengine"
export AI_MODEL="deepseek-v3-250324"

# Test-Befehl
gemini "Bitte stelle dich vor und sage mir, welches AI-Modell du bist."
```

### ğŸŒŠ Bailian testen

```bash
# Einheitliche Konfiguration verwenden
export AI_API_KEY="your-bailian-api-key"
export AI_ENGINE="bailian"
export AI_MODEL="qwen-plus"

# Test-Befehl
gemini "Bitte stelle dich vor und sage mir, welches AI-Modell du bist."
```

### ğŸ§  GLM testen

```bash
# Einheitliche Konfiguration verwenden
export AI_API_KEY="your-glm-api-key"
export AI_ENGINE="glm"
export AI_MODEL="glm-4"

# Test-Befehl
gemini "Bitte stelle dich vor und sage mir, welches AI-Modell du bist."
```

## ğŸ”§ Schneller Engine-Wechsel

```bash
# Zu OpenRouter Claude wechseln
export AI_ENGINE="openrouter"
export AI_MODEL="anthropic/claude-3.5-sonnet"
gemini "Hello Claude!"

# Zu Azure GPT-4 wechseln
export AI_ENGINE="azure"
export AI_MODEL="gpt-4"
gemini "Hello GPT-4!"

# Zu lokalem Ollama wechseln
export AI_ENGINE="ollama"
export AI_MODEL="llama3.2:latest"
gemini "Hello Llama!"

# Zu Volcengine DeepSeek wechseln
export AI_ENGINE="volcengine"
export AI_MODEL="deepseek-v3-250324"
gemini "Hello DeepSeek!"
```

## ğŸ—ï¸ Technische Architektur

### ğŸ¯ Multi-Engine-Factory-Pattern-Architektur

Dieses Projekt verwendet ein**Factory-Pattern**-Design und realisiert hochgradig erweiterbare Multi-AI-Engine-UnterstÃ¼tzungï¼š

```
ContentGeneratorFactory
â”œâ”€â”€ OpenrouterContentGenerator    (OpenRouter)
â”œâ”€â”€ AzureContentGenerator         (Azure OpenAI)
â”œâ”€â”€ OllamaContentGenerator        (Local Ollama)
â”œâ”€â”€ VolcengineContentGenerator    (Volcengine)
â”œâ”€â”€ BailianContentGenerator       (Alibaba Cloud Bailian)
â””â”€â”€ GlmContentGenerator           (Zhipu AI GLM)
```

### ğŸ”§ Kernfunktionen

âœ… **6 groÃŸe AI-Engines**: Einheitliche Verwaltung aller AI-Engines durch Factory-Pattern  
âœ… **Einheitliche Umgebungsvariablen**: `AI_API_KEY`ã€`AI_MODEL`ã€`AI_BASE_URL` gemeinsame Konfiguration  
âœ… **Automatische Formatkonvertierung**: Nahtlose Konvertierung zwischen Gemini-Format und verschiedenen Engine-API-Formaten  
âœ… **Streaming-Response-UnterstÃ¼tzung**: Alle Engines unterstÃ¼tzen Streaming und Non-Streaming Responses  
âœ… **Intelligente Fehlerbehandlung**: 30-Sekunden-Timeout-Schutz, detaillierte Fehlermeldungen  
âœ… **KonfigurationsprioritÃ¤t**: Einheitliche Konfiguration > Engine-spezifische Konfiguration > Standard-Konfiguration  
âœ… **Null-Konfigurationswechsel**: Engine-Wechsel mit einer Umgebungsvariable mÃ¶glich  

## ğŸ“‹ Lizenzhinweis

Dieses Projekt basiert auf [Google Gemini CLI](https://github.com/google-gemini/gemini-cli) und folgt den Apache 2.0-Lizenzanforderungenï¼š

### UrsprÃ¼ngliche Projektinformationen

- **UrsprÃ¼ngliches Projekt**: Google Gemini CLI
- **UrsprÃ¼ngliches Copyright**: Copyright 2025 Google LLC  
- **UrsprÃ¼ngliche Lizenz**: Apache License 2.0
- **UrsprÃ¼ngliches Repository**: https://github.com/google-gemini/gemini-cli

### Ã„nderungserklÃ¤rung

GemÃ¤ÃŸ Apache 2.0-Lizenz Abschnitt 4ï¼š

- âœ… UrsprÃ¼ngliche Apache 2.0-Lizenz beibehalten
- âœ… UrsprÃ¼ngliche Copyright-Hinweise beibehalten
- âœ… Alle Ã„nderungen klar markieren
- âœ… VollstÃ¤ndigen Lizenztext einbeziehen

## ğŸ”„ Migration von ursprÃ¼nglicher Gemini CLI

Wenn Sie von der ursprÃ¼nglichen Google Gemini CLI migrierenï¼š

1. **UrsprÃ¼ngliche Version deinstallieren**: `npm uninstall -g @google/gemini-cli`
2. **Diese Version installieren**: `npm install -g @catalystai/gemini-cli`
3. **API-SchlÃ¼ssel setzen**: `export AI_API_KEY="your-actual-api-key"`
4. **Engine auswÃ¤hlen**: `export AI_ENGINE="volcengine"` (oder andere Engine)
5. **Normal verwenden**: Alle Befehle bleiben unverÃ¤ndert

## ğŸ§ª Testskripte

Sofort einsatzbereite Testskripte fÃ¼r jede Engine. Diese Skripte verwenden Platzhalter-API-SchlÃ¼ssel, die Sie durch echte SchlÃ¼ssel ersetzen mÃ¼ssen.

### ğŸš€ Verwendung der Testskripte

#### Linux/macOS Benutzer

```bash
# AusfÃ¼hrungsrechte fÃ¼r Skripte vergeben
chmod +x test-*.sh

# Einzelne Engine testen
./test-openrouter.sh
./test-azure.sh
./test-ollama.sh
./test-volcengine.sh
./test-bailian.sh
./test-glm.sh

# Alle Engines testen
./test-all-engines.sh
```

#### Windows Benutzer

```powershell
# Einzelne Engine testen
.\test-volcengine.ps1
.\test-openrouter.ps1

# Oder direkt ausfÃ¼hren
powershell -ExecutionPolicy Bypass -File test-volcengine.ps1
```

#### Konfiguration

Ersetzen Sie vor dem AusfÃ¼hren der Testskripte die Platzhalter-API-SchlÃ¼ssel durch echte SchlÃ¼sselï¼š

```bash
# Bearbeiten Sie jedes Testskript und ersetzen Sie Platzhalter-API-SchlÃ¼ssel
export AI_API_KEY="your-actual-api-key-from-your-ai-provider"
```

### ğŸ“‹ VerfÃ¼gbare Testskripte

### ğŸŒ OpenRouter Testskript

```bash
#!/bin/bash
# test-openrouter.sh
export AI_API_KEY="your-openrouter-api-key"
export AI_ENGINE="openrouter"
export AI_MODEL="anthropic/claude-3.5-sonnet"

echo "Testing OpenRouter with Claude 3.5 Sonnet..."
gemini "Hello, please introduce yourself and tell me which AI model you are."
```

### â˜ï¸ Azure Testskript

```bash
#!/bin/bash
# test-azure.sh
export AI_API_KEY="your-azure-openai-api-key"
export AI_ENGINE="azure"
export AI_BASE_URL="https://your-resource.openai.azure.com"
export AI_MODEL="gpt-4"

echo "Testing Azure OpenAI with GPT-4..."
gemini "Hello, please introduce yourself and tell me which AI model you are."
```

### ğŸ¦™ Ollama Testskript

```bash
#!/bin/bash
# test-ollama.sh
export AI_ENGINE="ollama"
export AI_BASE_URL="http://localhost:11434"
export AI_MODEL="llama3.2:latest"

echo "Testing Ollama with Llama 3.2..."
gemini "Hello, please introduce yourself and tell me which AI model you are."
```

### ğŸ”¥ Volcengine Testskript

```bash
#!/bin/bash
# test-volcengine.sh
export AI_API_KEY="your-volcengine-api-key"
export AI_ENGINE="volcengine"
export AI_MODEL="deepseek-v3-250324"

echo "Testing Volcengine with DeepSeek V3..."
gemini "Bitte stelle dich vor und sage mir, welches AI-Modell du bist."
```

### ğŸŒŠ Bailian Testskript

```bash
#!/bin/bash
# test-bailian.sh
export AI_API_KEY="your-bailian-api-key"
export AI_ENGINE="bailian"
export AI_MODEL="qwen-plus"

echo "Testing Bailian with Qwen Plus..."
gemini "Bitte stelle dich vor und sage mir, welches AI-Modell du bist."
```

### ğŸ§  GLM Testskript

```bash
#!/bin/bash
# test-glm.sh
export AI_API_KEY="your-glm-api-key"
export AI_ENGINE="glm"
export AI_MODEL="glm-4"

echo "Testing GLM with GLM-4..."
gemini "Bitte stelle dich vor und sage mir, welches AI-Modell du bist."
```

### ğŸš€ Alle Engines Testskript

```bash
#!/bin/bash
# test-all-engines.sh

# Test-Funktion
test_engine() {
    local engine=$1
    local model=$2
    local api_key=$3
    local base_url=$4
    local prompt=$5
    
    echo "=========================================="
    echo "Testing $engine with $model"
    echo "=========================================="
    
    export AI_ENGINE="$engine"
    export AI_MODEL="$model"
    export AI_API_KEY="$api_key"
    
    if [ -n "$base_url" ]; then
        export AI_BASE_URL="$base_url"
    fi
    
    gemini "$prompt"
    echo ""
}

# Alle Engines testen
echo "ğŸŒ Testing OpenRouter (Claude 3.5 Sonnet)..."
test_engine "openrouter" "anthropic/claude-3.5-sonnet" "your-openrouter-api-key" "" "Hello, please introduce yourself and tell me which AI model you are. Please respond in English."

echo "â˜ï¸ Testing Azure OpenAI (GPT-4)..."
test_engine "azure" "gpt-4" "your-azure-openai-api-key" "https://your-resource.openai.azure.com" "Hello, please introduce yourself and tell me which AI model you are. Please respond in English."

echo "ğŸ¦™ Testing Ollama (Llama 3.2)..."
test_engine "ollama" "llama3.2:latest" "" "http://localhost:11434" "Hello, please introduce yourself and tell me which AI model you are. Please respond in English."

echo "ğŸ”¥ Testing Volcengine (DeepSeek V3)..."
test_engine "volcengine" "deepseek-v3-250324" "your-volcengine-api-key" "" "Bitte stelle dich vor und sage mir, welches AI-Modell du bist. Bitte antworte auf Deutsch."

echo "ğŸŒŠ Testing Bailian (Qwen Plus)..."
test_engine "bailian" "qwen-plus" "your-bailian-api-key" "" "Bitte stelle dich vor und sage mir, welches AI-Modell du bist. Bitte antworte auf Deutsch."

echo "ğŸ§  Testing GLM (GLM-4)..."
test_engine "glm" "glm-4" "your-glm-api-key" "" "Bitte stelle dich vor und sage mir, welches AI-Modell du bist. Bitte antworte auf Deutsch."

echo "âœ… All engines tested!"
```

## ğŸ”— Verwandte Links

- [UrsprÃ¼ngliches Projekt (Google Gemini CLI)](https://github.com/google-gemini/gemini-cli)
- [OpenRouter](https://openrouter.ai/)
- [Azure OpenAI](https://azure.microsoft.com/en-us/products/ai-services/openai-service)
- [Ollama](https://ollama.ai/)
- [ç«å±±å¼•æ“AIå¹³å°](https://www.volcengine.com/products/ai)
- [é˜¿é‡Œäº‘ç™¾ç‚¼](https://bailian.console.aliyun.com/)
- [æ™ºè°±AI](https://www.zhipuai.cn/)
- [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0)

## ğŸ› Problemberichterstattung

Wenn Sie Probleme haben, melden Sie diese bitte bei [GitHub Issues](https://github.com/chameleon-nexus/gemini-cli/issues).

## ğŸ¤ Beitragsrichtlinien

Code-BeitrÃ¤ge sind willkommen! Bitte stellen Sie sicherï¼š

1. Dem Code-Stil des ursprÃ¼nglichen Projekts zu folgen
2. Angemessene Tests einzuschlieÃŸen
3. Verwandte Dokumentation zu aktualisieren
4. Die Apache 2.0-Lizenzbedingungen einzuhalten

## ğŸ“ Changelog

### v0.0.3 (Aktuelle Version)
- âœ¨ **é˜¿é‡Œäº‘ç™¾ç‚¼-UnterstÃ¼tzung hinzugefÃ¼gt** - OpenAI-kompatibler Modus
- âœ¨ **Azure AI Foundry-UnterstÃ¼tzung** - Neuer Service-Endpunkt
- âœ¨ **Einheitliches Umgebungsvariablen-System** - `AI_API_KEY`ã€`AI_MODEL`ã€`AI_BASE_URL`
- âœ¨ **Ollama-Adapter-Optimierung** - Echter Streaming-Verarbeitung
- âœ¨ **GLM-Adapter-VervollstÃ¤ndigung** - æ™ºè°±AI GLM-4-UnterstÃ¼tzung
- ğŸ”§ **KonfigurationsprioritÃ¤t-Optimierung** - Einheitliche Konfiguration > Engine-spezifische Konfiguration
- ğŸ“š **VollstÃ¤ndige Testskripte** - UnabhÃ¤ngige Testskripte fÃ¼r jede Engine
- ğŸ› **Fehlerbehandlung verbessert** - Freundlichere Fehlermeldungen

### v0.0.2
- âœ¨ **Multi-Engine-UnterstÃ¼tzung** - OpenRouterã€Azureã€DashScopeã€GLMã€Ollama
- âœ¨ **Factory-Pattern-Architektur** - Hochgradig erweiterbares Design
- âœ¨ **Streaming-Response-UnterstÃ¼tzung** - Alle Engines unterstÃ¼tzen Streaming-Verarbeitung
- ğŸ“š **Detaillierte Dokumentation** - Multi-Engine-Nutzungsanleitung

### v0.0.1
- ğŸ‰ **Erste Version** - ç«å±±å¼•æ“AI-Integration
- âœ¨ **VollstÃ¤ndige KompatibilitÃ¤t** - VollstÃ¤ndig kompatibel mit ursprÃ¼nglicher Gemini CLI
- ğŸ”§ **Umgebungsvariablen-Konfiguration** - Flexible Konfigurationsoptionen
- ğŸ‡¨ğŸ‡³ **Chinesisch-Optimierung** - FÃ¼r chinesische GesprÃ¤che optimiert

## ğŸŒŸ Projekt-Highlights

- ğŸš€ **Weltpremiere**: Das erste einheitliche CLI-Tool mit UnterstÃ¼tzung fÃ¼r 6 groÃŸe AI-Engines
- ğŸ¯ **Null-Lernkosten**: Ein Befehl, alle Modelle
- ğŸ”„ **Intelligenter Wechsel**: Umgebungsvariablen-Steuerung, Engine-Wechsel in Sekunden
- ğŸŒ **Globale Abdeckung**: UnterstÃ¼tzt Mainstream-AI-Modelle aus China, USA und Europa
- ğŸ  **Lokale UnterstÃ¼tzung**: Ollama lokale Bereitstellung, Daten vollstÃ¤ndig privat
- ğŸ“Š **Unternehmensklasse**: VollstÃ¤ndige Fehlerbehandlung und Konfigurationsverwaltung

---

**Haftungsausschluss**: Dieses Projekt steht in keiner Verbindung zu Google, OpenRouter, Azure, Ollama, Volcengine, é˜¿é‡Œäº‘, æ™ºè°±AI oder anderen Unternehmen. Bitte beachten Sie bei der Nutzung die Servicebedingungen der jeweiligen Plattformen.